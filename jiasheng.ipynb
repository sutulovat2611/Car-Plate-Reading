{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.util import random_noise\n",
    "from imutils import grab_contours\n",
    "import copy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "OUTPUT_NEURONS = 3\n",
    "INPUT_NEURONS = 4\n",
    "HIDDEN_NEURONS = 4\n",
    "\n",
    "def Weight_Initialization():\n",
    "    # Initializing of the Weights. Random float number between -0.5 to 0.5 for weights.\n",
    "    np.random.seed(1)\n",
    "    inputs= np.random.uniform(-0.5, 0.5, size=( INPUT_NEURONS))\n",
    "    wji= np.random.uniform(-0.5, 0.5, size=(HIDDEN_NEURONS, INPUT_NEURONS))\n",
    "    wkj = np.random.uniform(-0.5, 0.5, size=(OUTPUT_NEURONS, HIDDEN_NEURONS))\n",
    "    bias_j = np.random.uniform(0, 1, size=(HIDDEN_NEURONS))\n",
    "    bias_k = np.random.uniform(0, 1, size=(OUTPUT_NEURONS))\n",
    "    targets = np.random.uniform(0, 1, size=(OUTPUT_NEURONS))\n",
    "    return inputs, wji,wkj,bias_j,bias_k,targets\n",
    "# def Read_Files():\n",
    "#     # Reading of Segmented Training Files, and Target Files.\n",
    "\n",
    "\n",
    "def Forward_Input_Hidden(inputs,wji, bias_j):\n",
    "    # Forward Propagation from Input -> Hidden Layer.\n",
    "    # Obtain the results at each neuron in the hidden layer.\n",
    "    # Calculate 𝑁𝑒𝑡𝑗and 𝑂𝑢𝑡𝑗\n",
    "\n",
    "    Netj = np.dot(inputs,wji.T) \n",
    "    print(\"Netj :\")\n",
    "    print(Netj)\n",
    "    Outj = 1/(1 + math.e**-(Netj + np.transpose(bias_j)))\n",
    "    print(\"Outj :\")\n",
    "    print(Outj)\n",
    "    return Netj,Outj\n",
    "\n",
    "def Forward_Hidden_Output(Netj,wkj, bias_k):\n",
    "    # Forward Propagation from Input -> Hidden Layer.\n",
    "    # Obtain the results at each neuron in the hidden layer.\n",
    "    # Calculate 𝑁𝑒𝑡kand 𝑂𝑢𝑡k\n",
    "\n",
    "    Netk = np.dot(Netj,wkj.T) \n",
    "    print(\"Netk :\")\n",
    "    print(Netk)\n",
    "    Outk = 1/(1 + math.e**-(Netk + np.transpose(bias_k)))\n",
    "    print(\"Outk :\")\n",
    "    print(Outk)\n",
    "    return Netk, Outk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Check_for_End(Outk, targets, user_set):\n",
    "    # Check whether the total error is less than the error set by the user or the number of iterations is reached.\n",
    "    # returns true or false\n",
    "    def Error_Correction(outs, targets):\n",
    "        total_error= ((outs - targets)**2)/2\n",
    "        return total_error\n",
    "    result = []\n",
    "    for i in range(len(Outk)):\n",
    "        if Error_Correction(Outk, targets)< user_set:\n",
    "            result \n",
    "\n",
    "    else: \n",
    "        return False\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Weight_Bias_Correction_Output(Outk, targets, Outj):\n",
    "    # Correction of Weights and Bias between Hidden and Output Layer.\n",
    "    # Calculate 𝑑𝑤𝑘𝑘𝑗 and 𝑑𝑏𝑘𝑘𝑗\n",
    "    dwkkj =  np.empty((0, len(Outk)))\n",
    "    for i in range(len(Outj)):\n",
    "        temp =(Outk - targets) * Outk*(1 - Outk) * Outj[i]\n",
    "        dwkkj = np.vstack([dwkkj,temp])\n",
    "    dbkkj = (Outk - targets) * Outk*(1 - Outk) \n",
    "    dwkkj = dwkkj.T\n",
    "    # print(dwkkj)\n",
    "    return dwkkj,dbkkj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Weight_Bias_Correction_Hidden(outj,outk,inputs,target,wkj):\n",
    "    # Correction of Weights and Bias between Input and Hidden Layer.\n",
    "    # Calculate 𝑑𝑤𝑗𝑗𝑖 and 𝑑𝑏𝑗𝑗𝑖\n",
    "    skl = (outk - target) * outk*(1-outk)\n",
    "    dwjji= np.multiply.outer(outj *(1 - outj) * np.dot(skl,wkj),inputs)\n",
    "    dbjii = outj *(1 - outj) * np.dot(skl,wkj)\n",
    "\n",
    "    return dwjji, dbjii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Weight_Bias_Update(wkj,dwkkj, bias_k, dbkkj, wji, dwjji,bias_j,dbjii ):\n",
    "    # Saving_Weights_Bias() implemented inside\n",
    "    # Update Weights and Bias.\n",
    "    # Calculate 𝑤𝑘𝑘𝑗+ and 𝑏𝑘𝑘𝑗+\n",
    "    n = 0.5\n",
    "    wkjj = wkj - n*dwkkj\n",
    "    bkkj = bias_k - n*dbkkj\n",
    "    print(\"wk+\")\n",
    "    print(wkjj)\n",
    "    print(\"bias_k+\")\n",
    "    print(bkkj)\n",
    "\n",
    "    # Calculate 𝑤𝑗𝑗𝑖+ and 𝑏𝑗𝑗𝑖+\n",
    "    wjji = wji - n *dwjji\n",
    "    bjji = bias_j - n* dbjii\n",
    "    print(\"wj+\")\n",
    "    print(wjji)\n",
    "    print(\"bias_j+\")\n",
    "    print(bjji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Saving_Weights_Bias():\n",
    "#     # Save 𝑤𝑘𝑘𝑗 and 𝑏𝑘𝑘𝑗\n",
    "#     # Save 𝑤𝑗𝑗𝑖 and 𝑏𝑗𝑗𝑖\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Netj :\n",
      "[-0.24 -0.41  0.52]\n",
      "Outj :\n",
      "[0.53991488 0.44769209 0.65021855]\n",
      "Netk :\n",
      "[0.16526677 0.05714176]\n",
      "Outk :\n",
      "[0.61426285 0.55160107]\n",
      "wk+\n",
      "[[-0.29451584  0.15454741  0.40660456]\n",
      " [ 0.38987751 -0.50839347  0.08780951]]\n",
      "bias_k+\n",
      "[0.31015745 0.1312517 ]\n",
      "wj+\n",
      "[[-0.80130992  0.19790413]\n",
      " [-0.49865269 -0.1978443 ]\n",
      " [ 0.40024883  0.40039813]]\n",
      "bias_j+\n",
      "[0.39738016 0.20269462 0.10049766]\n"
     ]
    }
   ],
   "source": [
    "# inputs, wji,wkj,bias_j,bias_k,target = Weight_Initialization()\n",
    "# inputs= np.array([0.2,0.5])\n",
    "# wji= np.array([[0.1,0.2],[0.3,0.4]])\n",
    "# wkj= np.array([[0.5,0.6],[0.7,0.8]])\n",
    "# bias_j = np.array([0.2,0.2])\n",
    "# bias_k = np.array([0.4,0.4])\n",
    "# target = np.array([0.2,0.8])\n",
    "inputs= np.array([0.5,0.8])\n",
    "wji= np.array([[-0.8,0.2],[-0.5,-0.2],[0.4,0.4]])\n",
    "wkj= np.array([[-0.3,0.15,0.4],[0.4,-0.5,0.1]])\n",
    "bias_j = np.array([0.4,0.2,0.1])\n",
    "bias_k = np.array([0.3,0.15])\n",
    "target = np.array([0.7,0.4])\n",
    "netj,outj = Forward_Input_Hidden(inputs, wji, bias_j)\n",
    "netk,outk = Forward_Hidden_Output(outj, wkj, bias_k)\n",
    "\n",
    "dwkkj,dbkkj = Weight_Bias_Correction_Output(outk,target, outj)\n",
    "\n",
    "dwjji, dbjii = Weight_Bias_Correction_Hidden(outj,outk,inputs,target,wkj)\n",
    "\n",
    "Weight_Bias_Update(wkj,dwkkj, bias_k, dbkkj, wji, dwjji,bias_j,dbjii)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
